{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32c916f9",
   "metadata": {},
   "source": [
    "# Card Generating DCGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8627e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import binascii\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "#import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7daad",
   "metadata": {},
   "source": [
    "What machine learning models are used for variable input and output sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6961b29",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNNs): RNNs are a class of neural networks that process sequential data one element at a time while maintaining an internal hidden state. They can handle variable-length sequences by iterating over the elements one by one.\n",
    "\n",
    "Long Short-Term Memory Networks (LSTMs) and Gated Recurrent Units (GRUs): These are variants of RNNs designed to mitigate the vanishing gradient problem and better capture long-range dependencies in sequences.\n",
    "\n",
    "Encoder-Decoder Models: These architectures consist of two main components: an encoder that processes the input sequence and a decoder that generates the output sequence. They are commonly used for sequence-to-sequence tasks like machine translation.\n",
    "\n",
    "Transformer: The Transformer architecture, introduced in the \"Attention is All You Need\" paper, is based on self-attention mechanisms. It has become a fundamental model in natural language processing tasks and allows for parallel processing of input and output sequences, making it particularly efficient for variable-length sequences.\n",
    "\n",
    "Attention-based Models: Attention mechanisms can be used in combination with other models (e.g., RNNs, LSTMs, or Transformers) to focus on specific parts of the input sequence when generating the output sequence. This helps the model effectively handle variable-sized inputs and outputs.\n",
    "\n",
    "Convolutional Sequence-to-Sequence Models: Inspired by convolutional neural networks, these models use 1D convolutions to process sequential data, allowing them to handle variable-length input and output sequences.\n",
    "\n",
    "Pointer Networks: Pointer networks can be used to generate sequences by selectively copying elements from the input sequence, which is especially useful when the output vocabulary is not fixed.\n",
    "\n",
    "Graph Neural Networks (GNNs): GNNs can handle variable input sizes when dealing with graph-structured data, as they operate on the graph's nodes and edges, which can have varying degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e81ed8",
   "metadata": {},
   "source": [
    "** Convolutional Sequence-to-Sequence Models might work **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb2238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Opening JSON file as a dictionary\n",
    "        with open('cards.collectible.json', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        # Create new list of strings\n",
    "        cardList = []\n",
    "        for i in data['allCards']:\n",
    "            if (i[\"type\"] == \"HERO\"):\n",
    "                continue\n",
    "            cardString = i['name'] \n",
    "            cardString += \" \" + i[\"cardClass\"] + \" \" + i[\"type\"]\n",
    "            cardString += \" \" + str(i[\"cost\"]) + \" mana\"\n",
    "            if (i[\"type\"] == \"MINION\"):\n",
    "                cardString += \" \" + str(i[\"attack\"]) + \"\\\\\" + str(i[\"health\"])\n",
    "            #cardString += \" \\\"\" + i[\"text\"] + \"\\\"\"\n",
    "            cardList.append(cardString)\n",
    "        # Closing file\n",
    "        f.close()\n",
    "        # Find the length of the largest string\n",
    "        #maxStringLength = len(cardList[1])\n",
    "        #for i in cardList:\n",
    "        #    if len(i) > maxStringLength:\n",
    "        #        maxStringLength = len(i)\n",
    "        #print(maxStringLength) # as of 7/29/2023, it is 56\n",
    "        # Make all strings equal size (64)\n",
    "        for i in range(len(cardList)):\n",
    "            while(len(cardList[i]) < 64):\n",
    "                cardList[i] += \" \"\n",
    "        # Create a list of tensors\n",
    "        self.tensorList = []\n",
    "        for i in range(len(cardList)):\n",
    "            characterTensors = []\n",
    "            for c in cardList[i]:\n",
    "                binaryCharacter = bin(ord(c))\n",
    "                #remove '0b' from beginning\n",
    "                binaryCharacter = binaryCharacter[2:-1]\n",
    "                binaryList = []\n",
    "                for j in range(8):\n",
    "                    if (j < len(binaryCharacter)):\n",
    "                        binaryList.append(int(binaryCharacter[j]))\n",
    "                    else:\n",
    "                        binaryList.append(0)   \n",
    "                characterTensors.append(binaryList)\n",
    "            self.tensorList.append(torch.tensor(characterTensors))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensorList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensorList[idx], 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577409fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = CustomImageDataset()\n",
    "#print(dataset.__len__())\n",
    "#print(len(dataset.__getitem__(0)[0]))\n",
    "#print(dataset.__getitem__(0)[0].shape)\n",
    "#print(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c42ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ef2f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5084, 1, 64, 8])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file as a dictionary\n",
    "with open('cards.collectible.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create new list of strings\n",
    "cardList = []\n",
    "for i in data['allCards']:\n",
    "    if (i[\"type\"] == \"HERO\"):\n",
    "        continue\n",
    "    cardString = i['name'] \n",
    "    cardString += \" \" + i[\"cardClass\"] + \" \" + i[\"type\"]\n",
    "    cardString += \" \" + str(i[\"cost\"]) + \" mana\"\n",
    "    if (i[\"type\"] == \"MINION\"):\n",
    "        cardString += \" \" + str(i[\"attack\"]) + \"\\\\\" + str(i[\"health\"])\n",
    "    #cardString += \" \\\"\" + i[\"text\"] + \"\\\"\"\n",
    "    cardList.append(cardString)\n",
    "# Closing file\n",
    "f.close()\n",
    "# Make all strings equal size (64)\n",
    "for i in range(len(cardList)):\n",
    "    while(len(cardList[i]) < 64):\n",
    "        cardList[i] += \" \"\n",
    "\n",
    "# Create a list of tensors\n",
    "tensorList = []\n",
    "for i in range(len(cardList)):\n",
    "    characterTensors = []\n",
    "    for c in cardList[i]:\n",
    "        binaryCharacter = bin(ord(c))\n",
    "        #remove '0b' from beginning\n",
    "        binaryCharacter = binaryCharacter[2:-1]\n",
    "        binaryList = []\n",
    "        for j in range(8):\n",
    "            if (j < len(binaryCharacter)):\n",
    "                binaryList.append(int(binaryCharacter[j]))\n",
    "            else:\n",
    "                binaryList.append(0)   \n",
    "        characterTensors.append(binaryList)\n",
    "    tensorList.append([characterTensors])\n",
    "\n",
    "data = torch.tensor(tensorList, dtype=torch.float32)\n",
    "print(data.shape)\n",
    "print(data.dtype)\n",
    "labels = torch.ones(len(cardList)) #.reshape([1, len(cardList)])\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45389fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the dataset from above\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)#,\n",
    "                                         #shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72194fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06346016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "#Input noise has size [128, 100, 1, 1]\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "            nn.Conv2d(nc, nc, 4, (1, 8), (2, 0), bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 8``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        binary_output = torch.where(output >= 0.5, torch.ones_like(output), torch.zeros_like(output))\n",
    "        return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee7fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake is  tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Get an output of the generator\n",
    "b_size = real_cpu.size(0)\n",
    "noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "fake = netG(noise)\n",
    "print(\"fake is \", fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9c83210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Conv2d(1, 1, kernel_size=(4, 4), stride=(1, 8), padding=(2, 0), bias=False)\n",
      "    (14): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32f369bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # torch.nn.Conv2d(in_channels, out_channels, \n",
    "            # kernel_size, stride=1, padding=0, dilation=1, groups=1, \n",
    "            # bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "            # input is ``(nc) x 64 x 8``\n",
    "            nn.Conv2d(nc, ndf, (4, 1), (2, 1), (1, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf) x 32 x 8``\n",
    "            nn.Conv2d(ndf, ndf * 2, (4, 1), (2, 1), (1, 0), bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*2) x 16 x 8``\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, (4, 1), (2, 1), (1, 0), bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        #Warning: Lack of communication between columns (7/30/2023)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba617f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 1), stride=(2, 1), padding=(1, 0), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 1), stride=(2, 1), padding=(1, 0), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 1), stride=(2, 1), padding=(1, 0), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "# like this: ``to mean=0, stdev=0.2``.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d327d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ``BCELoss`` function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01611cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, data in enumerate(dataloader, start=0):\n",
    "#    print(i)\n",
    "#    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "607c5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/5][0/40]\tLoss_D: 0.0000\tLoss_G: 12.5086\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
      "[1/5][0/40]\tLoss_D: 0.0000\tLoss_G: 12.7214\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
      "[2/5][0/40]\tLoss_D: 0.0000\tLoss_G: 12.9035\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
      "[3/5][0/40]\tLoss_D: 0.0000\tLoss_G: 13.0654\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
      "[4/5][0/40]\tLoss_D: 0.0000\tLoss_G: 13.2150\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        #print(\"data shape is\", real_cpu.shape)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        #print(\"output shape is\", output.shape)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        #noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        noise = torch.randint(2, (b_size, nz, 1, 1), dtype=torch.float, device=device)\n",
    "        #print(\"noise shape is\", noise.shape)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        #print(\"fake shape is\", fake.shape)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        #print(\"output shape is\", output.shape)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80d4ca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([92, 100, 1, 1])\n",
      "torch.Size([92, 100, 1, 92])\n",
      "torch.Size([92, 100, 1, 1])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "print(noise.shape)\n",
    "noise = torch.where(noise >= 0, torch.ones_like(output), torch.zeros_like(output))\n",
    "print(noise.shape)\n",
    "noise = torch.randint(2, (b_size, nz, 1, 1), dtype=torch.float, device=device)\n",
    "print(noise.shape)\n",
    "fake = netG(noise)\n",
    "print(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "single_data = next(dataiter)\n",
    "print(single_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(t):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700d85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
